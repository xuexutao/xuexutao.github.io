<!DOCTYPE html>
<html lang="zh-CN">
    
    <head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover" name="viewport" />
    <meta name="description" content="CUDA model learning" />
    <meta name="hexo-theme-A4" content="v1.9.6" />
    <link rel="alternate icon" type="image/webp" href="/img/man.jpg">
    <title>Xuext</title>

    
        
<link rel="stylesheet" href="/css/highlight/style1.css">

        
<link rel="stylesheet" href="/css/reset.css">

        
<link rel="stylesheet" href="/css/markdown.css">

        
<link rel="stylesheet" href="/css/fonts.css">
 
         <!--注意：首页既不是post也不是page-->
        
        
        
<link rel="stylesheet" href="/css/ui.css">
 
        
<link rel="stylesheet" href="/css/style.css">


        
            <!--返回顶部css-->
            
<link rel="stylesheet" href="/css/returnToTop.css">

            
<link rel="stylesheet" href="/css/unicons.css">

        
        
            <!--目录-->
            
<link rel="stylesheet" href="/css/toc.css">

        
    

    
        
<link rel="stylesheet" href="/css/returnToLastPage.css">

    
    
   
<link rel="stylesheet" href="/css/lightgallery-bundle.min.css">


<meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>
    
    
        <style>
            .index-main{
                max-width:  880px;
            }
        </style>

    
    



    

    
    

    
    
    
    <body>
        <script src="/js/darkmode-js.min.js"></script>
        
        
            <div class="left-toc-container">
                <nav id="toc" class="bs-docs-sidebar"></nav>
            </div>
        
        <div class="paper">
            
            
            
            
                <div class="shadow-drop-2-bottom paper-main">
                    


<div class="header">
    <div class="header-container">
        <img style="
        width: 56px;
        height: auto;" alt="^-^" cache-control="max-age=86400" class="header-img" src="/img/man.jpg" width="10%"></img>
        <div class="header-content">
            <a class="logo" href="/">Xuext</a> 
            <span class="description">beihang University</span> 
        </div>
        
    </div>
    
   
    <ul class="nav">
        
            
                <li><a href="/">首页</a></li>
            
        
            
                <li><a href="/list/">⛰️文章</a></li>
            
        
            
                <li><a href="/categories/">🌬️分类</a></li>
            
        
    </ul>
</div> 
        
                    
                    

                    
                    
                    
                    <!--说明是文章post页面-->
                    
                        <div class="post-main">
    

    
        
            
                <div class="post-main-title" style="text-align: center;">
                    CUDA model learning
                </div>
            
        
      
    

    

        
            <div class="post-head-meta-center">
        
                
                    <span>最近更新：2024-10-05</span> 
                
                
                    
                        &nbsp; | &nbsp;
                    
                     <span>字数总计：850</span>
                
                
                    
                        &nbsp; | &nbsp;
                    
                    <span>阅读估时：3分钟</span>
                
                
                    
                        &nbsp; | &nbsp;
                    
                    <span id="busuanzi_container_page_pv">
                        阅读量：<span id="busuanzi_value_page_pv"></span>次
                    </span>
                
            </div>
    

    <div class="post-md">
        
            
                <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#cuda"><span class="post-toc-text">CUDA</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E6%A0%B8%E5%87%BD%E6%95%B0kernel-function"><span class="post-toc-text">核函数（Kernel function）</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="post-toc-text">⭐️线程模型</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%BA%BF%E7%A8%8B%E5%85%A8%E5%B1%80%E7%B4%A2%E5%BC%95%E8%AE%A1%E7%AE%97"><span class="post-toc-text">线程全局索引计算</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#nvcc%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B%E4%B8%8Egpu%E8%AE%A1%E7%AE%97%E8%83%BD%E5%8A%9B"><span class="post-toc-text">NVCC编译流程与GPU计算能力</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%9F%A9%E9%98%B5%E5%8A%A0%E6%B3%95"><span class="post-toc-text">矩阵加法</span></a></li></ol></li></ol></li></ol>
            
        
        <div class=".article-gallery"><h1 id="cuda">CUDA</h1>
<p>CPU上的主机代码</p>
<p>GPU上的设备代码</p>
<p>主机对设备的调用通过核函数//</p>
<h2 id="核函数kernel-function">核函数（Kernel function）</h2>
<p>1、核函数在GPU上并行执行</p>
<p>2、注意：</p>
<p>​ （1）限定词 <code>__global__</code>修饰</p>
<p>​ （2）返回值必须为void</p>
<p>3、形式</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel_function</span><span class="params">(arg)</span></span>{</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"hello world from the GPU"</span>);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">//-----</span></span><br><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">kernel_function</span><span class="params">()</span></span>{</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">"hello world from the GPU"</span>);</span><br><span class="line">}</span><br></pre></td></tr></table></figure>
<blockquote>
<p>核函数只能访问GPU内存</p>
<p>核函数不能使用变长参数（明确参数_<strong>个数</strong>_），不能使用静态变量、不能使用函数指针，不支持iostream</p>
<p>核函数具有异步性（调用时只是启动了kernel函数）</p>
</blockquote>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>{</span><br><span class="line">	hello_from_gpu&lt;&lt;&lt;<span class="number">1</span>,<span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>(); <span class="comment">// 等上面的CUDA进程执行完毕   主机与设备的同步</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure>
<h2 id="线程模型">⭐️线程模型</h2>
<p>线程模型结构</p>
<p>​ （1）grid。网格（2）block。线程块</p>
<p><a href="image-20240608234810614.png" class="gallery-item" style="box-shadow: none;"> <img src="image-20240608234810614.png" style="zoom:30%;"></a></p>
<ul>
<li><p>线程分块是逻辑上分块，物理上不分块</p></li>
<li><p>配置线程&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;</p></li>
<li><p>最大允许线程块大小1024</p></li>
<li><p>最大允许网格大小<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="6.816ex" height="2.072ex" role="img" focusable="false" viewBox="0 -833.9 3012.6 915.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(533,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g></g><g data-mml-node="mo" transform="translate(1512.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2512.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container></span>（针对一维线程模型）</p></li>
</ul>
<blockquote>
<p>### 一维模型</p>
<ol type="1">
<li>每个线程在核函数中都有一个唯一的身份标识: （线程块ID）<strong><span style="color:blue">Idx = threadIdx.x + blockIdx.x * blockDim.x</span></strong></li>
<li>每个线程的唯一标识由这两个&lt;&lt;&lt;grid_size，block_size&gt;&gt;&gt;确定;grid size，block size保存在内建变量(build-in variable)，目前考虑的是一维的情况:
<ol type="1">
<li><span style="color:red"><strong>gridDim.x</strong></span>:该变量的数值等于执行配置中变量grid size的值</li>
<li><span style="color:red"><strong>blockDim.x</strong></span>:该变量的数值等于执行配置中变量block size的值</li>
</ol></li>
<li><strong>线程索引</strong>保存成内建变量( build-in variable)「只在核函数中使用，其他地方无用」
<ol type="1">
<li><span style="color:red"><strong>blockldx.x</strong></span>:该变量指定一个线程在一个网格中的线程块索引值，范围为0~ gridDim.x-1;</li>
<li><span style="color:red"><strong>threadldx.x</strong></span>:该变量指定一个线程在一个线程块中的线程索引值，范围为0~ blockDim.x-1。</li>
</ol></li>
</ol>
<p>但是：</p>
<p><strong>blockIdx, threadIdx</strong> 都是uint3的变量，支持.x. .y. .z，最多三维</p>
</blockquote>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">hello_from_GPU</span><span class="params">()</span></span>{</span><br><span class="line">	<span class="type">const</span> <span class="type">int</span> bid = blockIdx.x;</span><br><span class="line">  <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">  <span class="type">const</span> <span class="type">int</span> id = threadIdx + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"hello world from block %d and thread %d, global id %d \n"</span>, bid, tid, id);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>{</span><br><span class="line">	hello_from_GPU&lt;&lt;&lt;<span class="number">2</span>,<span class="number">4</span>&gt;&gt;&gt;();</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure>
<blockquote>
<p><em>多维网格和线程块定义：</em></p>
<p>​ dim3 grid_size(Gx, Gy, Gz);</p>
<p>​ dim3 block_size(Bx, By, Bz);</p>
<p>标识都是横着的--》 <strong>block和grid同理</strong></p>
<p>Dim3 grid_size(3,2,1); # x为3，y为2</p>
<p>​ [(0,0), (1,0), (2,0), # x, y。 <strong><em>横着为x竖着为y</em></strong></p>
<p>​ (0,1), (1,1), (2,1)]</p>
<p>int tid = threadIdx.y*blockDim.x + threadIdx.x; # 在一个block中的threadID</p>
<p>int bid = threadIdx.y*gridDim.x + blockIdx.x; # 在一个grid的blockID</p>
</blockquote>
<h3 id="线程全局索引计算">线程全局索引计算</h3>
<p>一维网格</p>
<p><a href="image-20240609132011041.png" title="image-20240609132011041" class="gallery-item" style="box-shadow: none;"> <img src="image-20240609132011041.png" alt="image-20240609132011041" style="zoom:25%;"></a></p>
<p>二维网格</p>
<p><a href="image-20240609132103606.png" title="image-20240609132103606" class="gallery-item" style="box-shadow: none;"> <img src="image-20240609132103606.png" alt="image-20240609132103606" style="zoom:30%;"></a></p>
<p>id = 41</p>
<p>三维网格</p>
<p><a href="image-20240609132322427.png" title="image-20240609132322427" class="gallery-item" style="box-shadow: none;"> <img src="image-20240609132322427.png" alt="image-20240609132322427" style="zoom:30%;"></a></p>
<h3 id="nvcc编译流程与gpu计算能力">NVCC编译流程与GPU计算能力</h3>
<p><a href="image-20240609132623882.png" title="image-20240609132623882" class="gallery-item" style="box-shadow: none;"> <img src="image-20240609132623882.png" alt="image-20240609132623882" style="zoom:30%;"></a></p>
<h3 id="矩阵加法">矩阵加法</h3>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">function</span><span class="params">()</span></span>{</span><br><span class="line">	...</span><br><span class="line">  核函数</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>{</span><br><span class="line">	设置GPU设备；</span><br><span class="line">  分配主机和设备内存</span><br><span class="line">  初始化主机中的数据</span><br><span class="line">  数据从主机复制到设备</span><br><span class="line">  调用核函数在设备中进行计算</span><br><span class="line">  将计算得到的数据传给主机</span><br><span class="line">  释放主机与设备内存</span><br><span class="line">}</span><br></pre></td></tr></table></figure>
<p>1、设置GPU设备</p>
<p>运行时API</p>
<blockquote>
<p>cudaGetDeviceCount(). 可使用显卡数量。 ===cudaSuccess</p>
<p>cudaSetDevice(). 设置GPU执行时使用设备</p>
</blockquote>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">setGPU</span><span class="params">()</span></span>{</span><br><span class="line">	<span class="type">int</span> idevice = <span class="number">0</span>;</span><br><span class="line">  cudaError_t errot = <span class="built_in">cudaGetDeviceCount</span>(&amp;idevice);</span><br><span class="line">    </span><br><span class="line">  <span class="keyword">if</span>(error != cudaSuccess || idevice == <span class="number">0</span>){</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"No cuda campatable Gpu found!"</span>);</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">  }<span class="keyword">else</span>{</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"the count of Gpu is %d"</span>, idevice);</span><br><span class="line">  }</span><br><span class="line">    </span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="type">int</span> idev = <span class="number">0</span>;</span><br><span class="line">  error = <span class="built_in">cudaSetDevice</span>(idev);</span><br><span class="line">  <span class="keyword">if</span>(error != cudaSuccess){</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"fail to set Gpu 0 for computing"</span>);</span><br><span class="line">  	<span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">  }<span class="keyword">else</span>{</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"success"</span>);</span><br><span class="line">  }</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure>
<p>内存初始化</p>
<p><a href="image-20240609133914327.png" title="image-20240609133914327" class="gallery-item" style="box-shadow: none;"> <img src="image-20240609133914327.png" alt="image-20240609133914327" style="zoom:30%;"></a></p>
<p>内存释放</p>
<p><a href="image-20240609133938634.png" title="image-20240609133938634" class="gallery-item" style="box-shadow: none;"> <img src="image-20240609133938634.png" alt="image-20240609133938634" style="zoom:30%;"></a></p>
<p>线程组织管理</p>
<p>网格和线程块限制</p>
</div>
    </div>

    <div class="post-meta">
        <i>
        
            <span>2024-10-03</span>
            
                <span>该篇文章被 Xue xt</span>
            
            
             
                <span>归为分类:
                    
                    
                        <a href='/categories/CS/'>
                            CS
                        </a>
                    
                </span>
            
        
        </i>
    </div>
    <br>
    
    
        
            
    
            <div class="post-footer-pre-next">
                
                    <span>上一篇：<a href='/2024/10/03/FOURIER/'>FOURIER</a></span>
                

                
            </div>
    
        
    

    
        

     
</div>



                                      
                    
                    
                    <div class="footer">
    
        <span> 
            © 2001-2024 Xuext 

            
                

            
        </span>
       
    
</div>



<!--这是指一条线往下的内容-->
<div class="footer-last">
    
            <span>🌊看过大海的人不会忘记海的广阔🌊</span>
            
                <span class="footer-last-span-right"><i>本站由<a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/index.html">Hexo</a>驱动｜使用<a target="_blank" rel="noopener" href="https://github.com/HiNinoJay/hexo-theme-A4">Hexo-theme-A4</a>主题</i></span>
            
    
</div>


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>

    <!--目录-->
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.7.2/jquery.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tocify/1.9.0/javascripts/jquery.tocify.min.js" type="text/javascript" ></script>
        
<script src="/js/toc.js"></script>

    

    
<script src="/js/randomHeaderContent.js"></script>

    <!--回到顶部按钮-->
    
        
<script src="/js/returnToTop.js"></script>

    

    
        
<script src="/js/returnToLastPage.js"></script>

    





<script src="/js/lightgallery/lightgallery.umd.min.js"></script>



<script src="/js/lightgallery/plugins/lg-thumbnail.umd.min.js"></script>



<script src="/js/lightgallery/plugins/lg-fullscreen.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-autoplay.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-zoom.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-rotate.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-paper.umd.min.js"></script>




<script type="text/javascript">
     
    if (typeof lightGallery !== "undefined") {
        var options1 = {
            selector: '.gallery-item',
            plugins: [lgThumbnail, lgFullscreen, lgAutoplay, lgZoom, lgRotate, lgPager], // 启用插件
            thumbnail: true,          // 显示缩略图
            zoom: true,               // 启用缩放功
            rotate: true,             // 启用旋转功能能
            autoplay: true,        // 启用自动播放功能
            fullScreen: true,      // 启用全屏功能
            pager: false, //页码,
            zoomFromOrigin: true,   // 从原始位置缩放
            actualSize: true,       // 启用查看实际大小的功能
            enableZoomAfter: 300,    // 延迟缩放，确保图片加载完成后可缩放
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options1); // 修复选择器
    }
    
</script>


    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> 

                </div>
            
            
                <!-- 回到顶部的按钮-->  
                <div class="progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
            
                <!-- 返回的按钮-->  
                <div class="return-to-last-progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
    </body>
</html>